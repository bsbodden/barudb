{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fence Pointer Performance Analysis\n",
    "\n",
    "This notebook analyzes the performance of different fence pointer implementations in our LSM tree, focusing especially on the Eytzinger layout implementation.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Configure plot styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('deep')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Benchmark Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the benchmark results\n",
    "results_file = '../benchmarks/fence_bench_results_latest.csv'\n",
    "scaling_file = '../benchmarks/fence_bench_scaling_latest.csv'\n",
    "range_sizes_file = '../benchmarks/fence_bench_range_sizes_latest.csv'\n",
    "\n",
    "# Load the main results\n",
    "df = pd.read_csv(results_file)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the scaling results\n",
    "scaling_df = pd.read_csv(scaling_file)\n",
    "\n",
    "# Display the scaling data\n",
    "scaling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Range Size Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the range size results\n",
    "range_sizes_df = pd.read_csv(range_sizes_file)\n",
    "\n",
    "# Display the range size data\n",
    "range_sizes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison - Point Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for point query time data\n",
    "point_query_df = df[(df['QueryType'] == 'Point') & (df['MetricType'] == 'Time')].copy()\n",
    "\n",
    "# Order implementations for consistent plotting\n",
    "implementation_order = ['Standard', 'FastLane', 'Eytzinger', 'Basic_Eytzinger', 'SIMD_Eytzinger', 'Full_Eytzinger']\n",
    "point_query_df['Implementation'] = pd.Categorical(point_query_df['Implementation'], categories=implementation_order, ordered=True)\n",
    "point_query_df = point_query_df.sort_values('Implementation')\n",
    "\n",
    "# Create a bar chart for point query performance\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Implementation', y='Value', data=point_query_df, palette='deep')\n",
    "plt.title('Point Query Performance of Fence Pointer Implementations', fontsize=16)\n",
    "plt.xlabel('Implementation', fontsize=14)\n",
    "plt.ylabel('Time per Query (ns)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, p in enumerate(plt.gca().patches):\n",
    "    plt.gca().annotate(f'{float(p.get_height()):.2f}', \n",
    "                        (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha = 'center', va = 'bottom', \n",
    "                        xytext = (0, 5), textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_point_query.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison - Range Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for range query time data\n",
    "range_query_df = df[(df['QueryType'] == 'Range') & (df['MetricType'] == 'Time')].copy()\n",
    "\n",
    "# Create a bar chart for range query performance\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='Implementation', y='Value', data=range_query_df, palette='deep')\n",
    "plt.title('Range Query Performance of Fence Pointer Implementations', fontsize=16)\n",
    "plt.xlabel('Implementation', fontsize=14)\n",
    "plt.ylabel('Time per Range Query (ns)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, p in enumerate(plt.gca().patches):\n",
    "    plt.gca().annotate(f'{float(p.get_height()):.2f}', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha = 'center', va = 'bottom', \n",
    "                      xytext = (0, 5), textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_range_query.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement Over Standard Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for improvement data\n",
    "improvement_df = df[df['MetricType'] == 'Improvement'].copy()\n",
    "\n",
    "# Create a consistent order for implementations\n",
    "implementation_order = ['FastLane', 'Eytzinger', 'Basic_Eytzinger', 'SIMD_Eytzinger', 'Full_Eytzinger']\n",
    "improvement_df['Implementation'] = pd.Categorical(improvement_df['Implementation'], categories=implementation_order, ordered=True)\n",
    "improvement_df = improvement_df.sort_values(['QueryType', 'Implementation'])\n",
    "\n",
    "# Create a grouped bar chart for improvements\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Implementation', y='Value', hue='QueryType', data=improvement_df, palette='deep')\n",
    "plt.title('Performance Improvement Over Standard Fence Pointers', fontsize=16)\n",
    "plt.xlabel('Implementation', fontsize=14)\n",
    "plt.ylabel('Improvement (%)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Query Type', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, p in enumerate(plt.gca().patches):\n",
    "    plt.gca().annotate(f'{float(p.get_height()):.1f}%', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha = 'center', va = 'bottom' if p.get_height() >= 0 else 'top', \n",
    "                      xytext = (0, 5 if p.get_height() >= 0 else -15), textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_improvement.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for memory ratio data\n",
    "memory_df = df[df['MetricType'] == 'MemoryRatio'].copy()\n",
    "\n",
    "# Create a bar chart for memory usage\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x='Implementation', y='Value', data=memory_df, palette='deep')\n",
    "plt.title('Memory Usage Relative to Standard Fence Pointers', fontsize=16)\n",
    "plt.xlabel('Implementation', fontsize=14)\n",
    "plt.ylabel('Memory Ratio (x Standard)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=1.0, color='r', linestyle='--', label='Standard Memory Usage')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, p in enumerate(plt.gca().patches):\n",
    "    plt.gca().annotate(f'{float(p.get_height()):.2f}x', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha = 'center', va = 'bottom', \n",
    "                      xytext = (0, 5), textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_memory.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a line chart to show scaling with dataset size\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Convert Size to numeric and set as index\n",
    "scaling_df['Size'] = pd.to_numeric(scaling_df['Size'])\n",
    "scaling_df = scaling_df.set_index('Size')\n",
    "\n",
    "# Plot the three implementation lines\n",
    "plt.plot(scaling_df.index, scaling_df['Standard_ns'], 'o-', linewidth=2, label='Standard')\n",
    "plt.plot(scaling_df.index, scaling_df['FastLane_ns'], 's-', linewidth=2, label='FastLane')\n",
    "plt.plot(scaling_df.index, scaling_df['Eytzinger_ns'], '^-', linewidth=2, label='Eytzinger')\n",
    "\n",
    "# Set x-axis to log scale for clearer visualization\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Fence Pointer Performance Scaling with Dataset Size', fontsize=16)\n",
    "plt.xlabel('Dataset Size (elements)', fontsize=14)\n",
    "plt.ylabel('Time per Point Query (ns)', fontsize=14)\n",
    "plt.xticks(scaling_df.index, [f'{s:,}' for s in scaling_df.index], fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Add data points\n",
    "for i, size in enumerate(scaling_df.index):\n",
    "    plt.annotate(f'{scaling_df.loc[size, \"Standard_ns\"]:.2f}', \n",
    "                 (size, scaling_df.loc[size, \"Standard_ns\"]),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), ha='left')\n",
    "    plt.annotate(f'{scaling_df.loc[size, \"FastLane_ns\"]:.2f}', \n",
    "                 (size, scaling_df.loc[size, \"FastLane_ns\"]),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), ha='left')\n",
    "    plt.annotate(f'{scaling_df.loc[size, \"Eytzinger_ns\"]:.2f}', \n",
    "                 (size, scaling_df.loc[size, \"Eytzinger_ns\"]),\n",
    "                 textcoords=\"offset points\", xytext=(5, 5), ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_scaling.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance by Range Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a bar chart for performance by range size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a twin-axis plot for both time and improvement\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot time data on the first axis\n",
    "sns.barplot(x='RangeSize', y='Standard_ns', data=range_sizes_df, color='steelblue', alpha=0.7, ax=ax1, label='Standard')\n",
    "sns.barplot(x='RangeSize', y='Eytzinger_ns', data=range_sizes_df, color='forestgreen', alpha=0.7, ax=ax1, label='Eytzinger')\n",
    "\n",
    "# Plot improvement data on the second axis\n",
    "sns.pointplot(x='RangeSize', y='Improvement_pct', data=range_sizes_df, color='red', ax=ax2, label='Improvement (%)')\n",
    "\n",
    "# Set labels and title\n",
    "ax1.set_title('Range Query Performance by Range Size', fontsize=16)\n",
    "ax1.set_xlabel('Range Size Category', fontsize=14)\n",
    "ax1.set_ylabel('Time per Range Query (ns)', fontsize=14)\n",
    "ax2.set_ylabel('Improvement (%)', fontsize=14, color='red')\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=12)\n",
    "ax2.tick_params(axis='y', labelsize=12, colors='red')\n",
    "\n",
    "# Add a legend\n",
    "handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(handles1 + handles2, labels1 + labels2, loc='upper left', fontsize=12)\n",
    "\n",
    "# Add data annotations\n",
    "for i, row in range_sizes_df.iterrows():\n",
    "    ax1.annotate(f'{row[\"Standard_ns\"]:.2f}', \n",
    "               (i-0.2, row[\"Standard_ns\"]/2), \n",
    "               ha='center', color='white', fontweight='bold')\n",
    "    ax1.annotate(f'{row[\"Eytzinger_ns\"]:.2f}', \n",
    "               (i+0.2, row[\"Eytzinger_ns\"]/2), \n",
    "               ha='center', color='white', fontweight='bold')\n",
    "    ax2.annotate(f'{row[\"Improvement_pct\"]:.1f}%', \n",
    "               (i, row[\"Improvement_pct\"]+5), \n",
    "               ha='center', va='bottom', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_range_sizes.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for the optimization comparisons\n",
    "optimization_df = df[(df['Implementation'].isin(['Basic_Eytzinger', 'SIMD_Eytzinger', 'Full_Eytzinger'])) & \n",
    "                     (df['MetricType'] == 'Time')].copy()\n",
    "\n",
    "# Create a more readable version of the implementation names\n",
    "implementation_mapping = {\n",
    "    'Basic_Eytzinger': 'Basic Eytzinger',\n",
    "    'SIMD_Eytzinger': 'SIMD-Only',\n",
    "    'Full_Eytzinger': 'Fully Optimized'\n",
    "}\n",
    "optimization_df['Implementation'] = optimization_df['Implementation'].map(implementation_mapping)\n",
    "\n",
    "# Order implementations for consistent plotting\n",
    "implementation_order = ['Basic Eytzinger', 'SIMD-Only', 'Fully Optimized']\n",
    "optimization_df['Implementation'] = pd.Categorical(optimization_df['Implementation'], categories=implementation_order, ordered=True)\n",
    "optimization_df = optimization_df.sort_values(['QueryType', 'Implementation'])\n",
    "\n",
    "# Create a grouped bar chart for optimization impact\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Implementation', y='Value', hue='QueryType', data=optimization_df, palette='deep')\n",
    "plt.title('Impact of Optimizations on Eytzinger Fence Pointers', fontsize=16)\n",
    "plt.xlabel('Implementation', fontsize=14)\n",
    "plt.ylabel('Time per Query (ns)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Query Type', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for i, p in enumerate(plt.gca().patches):\n",
    "    plt.gca().annotate(f'{float(p.get_height()):.2f}', \n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                      ha = 'center', va = 'bottom', \n",
    "                      xytext = (0, 5), textcoords = 'offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../benchmarks/fence_pointer_optimization_impact.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a summary table for point queries\n",
    "point_summary = df[(df['QueryType'] == 'Point') & (df['MetricType'].isin(['Time', 'Improvement']))].copy()\n",
    "point_summary = point_summary.pivot(index='Implementation', columns='MetricType', values='Value')\n",
    "point_summary = point_summary.reset_index()\n",
    "\n",
    "# Create a summary table for range queries\n",
    "range_summary = df[(df['QueryType'] == 'Range') & (df['MetricType'].isin(['Time', 'Improvement']))].copy()\n",
    "range_summary = range_summary.pivot(index='Implementation', columns='MetricType', values='Value')\n",
    "range_summary = range_summary.reset_index()\n",
    "\n",
    "# Create a memory usage summary\n",
    "memory_summary = df[df['MetricType'] == 'MemoryRatio'].copy()\n",
    "memory_summary = memory_summary[['Implementation', 'Value']].rename(columns={'Value': 'MemoryRatio'})\n",
    "\n",
    "# Merge all summaries\n",
    "summary = pd.merge(point_summary, range_summary, on='Implementation', suffixes=('_Point', '_Range'))\n",
    "summary = pd.merge(summary, memory_summary, on='Implementation', how='left')\n",
    "\n",
    "# Format the summary for the report\n",
    "summary_formatted = summary.copy()\n",
    "summary_formatted['Time_Point'] = summary_formatted['Time_Point'].apply(lambda x: f'{float(x):.2f} ns' if not pd.isna(x) else 'N/A')\n",
    "summary_formatted['Time_Range'] = summary_formatted['Time_Range'].apply(lambda x: f'{float(x):.2f} ns' if not pd.isna(x) else 'N/A')\n",
    "summary_formatted['Improvement_Point'] = summary_formatted['Improvement_Point'].apply(lambda x: f'{float(x):+.1f}%' if not pd.isna(x) else 'N/A')\n",
    "summary_formatted['Improvement_Range'] = summary_formatted['Improvement_Range'].apply(lambda x: f'{float(x):+.1f}%' if not pd.isna(x) else 'N/A')\n",
    "summary_formatted['MemoryRatio'] = summary_formatted['MemoryRatio'].apply(lambda x: f'{float(x):.2f}x' if not pd.isna(x) else '1.00x')\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary_formatted = summary_formatted.rename(columns={\n",
    "    'Implementation': 'Implementation',\n",
    "    'Time_Point': 'Point Query Time',\n",
    "    'Time_Range': 'Range Query Time',\n",
    "    'Improvement_Point': 'Point Improvement',\n",
    "    'Improvement_Range': 'Range Improvement',\n",
    "    'MemoryRatio': 'Memory Usage Ratio'\n",
    "})\n",
    "\n",
    "# Display and save the summary\n",
    "display(summary_formatted)\n",
    "summary_formatted.to_csv('../benchmarks/fence_pointer_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Statistics for the Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract key statistics for the report\n",
    "# Best point query performance\n",
    "point_best_time = point_query_df.loc[point_query_df['Value'].idxmin()]\n",
    "point_best_impl = point_best_time['Implementation']\n",
    "point_best_time_val = point_best_time['Value']\n",
    "\n",
    "# Best range query performance\n",
    "range_best_time = range_query_df.loc[range_query_df['Value'].idxmin()]\n",
    "range_best_impl = range_best_time['Implementation']\n",
    "range_best_time_val = range_best_time['Value']\n",
    "\n",
    "# Eytzinger vs Standard improvement\n",
    "eytzinger_point_improvement = df[(df['Implementation'] == 'Eytzinger') & \n",
    "                                (df['QueryType'] == 'Point') & \n",
    "                                (df['MetricType'] == 'Improvement')]['Value'].values[0]\n",
    "eytzinger_range_improvement = df[(df['Implementation'] == 'Eytzinger') & \n",
    "                                (df['QueryType'] == 'Range') & \n",
    "                                (df['MetricType'] == 'Improvement')]['Value'].values[0]\n",
    "\n",
    "# Memory efficiency\n",
    "eytzinger_memory = df[(df['Implementation'] == 'Eytzinger') & \n",
    "                     (df['MetricType'] == 'MemoryRatio')]['Value'].values[0]\n",
    "\n",
    "# Best improvement for point and range queries\n",
    "best_point_improvement = improvement_df.loc[improvement_df[improvement_df['QueryType'] == 'Point']['Value'].idxmax()]\n",
    "best_range_improvement = improvement_df.loc[improvement_df[improvement_df['QueryType'] == 'Range']['Value'].idxmax()]\n",
    "\n",
    "# Print key statistics\n",
    "print(f\"Best point query implementation: {point_best_impl} ({point_best_time_val:.2f} ns)\")\n",
    "print(f\"Best range query implementation: {range_best_impl} ({range_best_time_val:.2f} ns)\")\n",
    "print(f\"Eytzinger vs Standard point queries: {eytzinger_point_improvement:+.1f}%\")\n",
    "print(f\"Eytzinger vs Standard range queries: {eytzinger_range_improvement:+.1f}%\")\n",
    "print(f\"Eytzinger memory ratio: {eytzinger_memory:.2f}x Standard\")\n",
    "print(f\"Best point query improvement: {best_point_improvement['Implementation']} ({best_point_improvement['Value']:+.1f}%)\")\n",
    "print(f\"Best range query improvement: {best_range_improvement['Implementation']} ({best_range_improvement['Value']:+.1f}%)\")\n",
    "\n",
    "# Generate key stats CSV for the report\n",
    "key_stats = {\n",
    "    \"Metric\": [\n",
    "        \"Best Point Query Implementation\",\n",
    "        \"Best Range Query Implementation\",\n",
    "        \"Eytzinger Point Query Improvement\",\n",
    "        \"Eytzinger Range Query Improvement\",\n",
    "        \"Eytzinger Memory Usage\",\n",
    "        \"Best Point Query Implementation\",\n",
    "        \"Best Range Query Implementation\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        f\"{point_best_impl} ({point_best_time_val:.2f} ns)\",\n",
    "        f\"{range_best_impl} ({range_best_time_val:.2f} ns)\",\n",
    "        f\"{eytzinger_point_improvement:+.1f}%\",\n",
    "        f\"{eytzinger_range_improvement:+.1f}%\",\n",
    "        f\"{eytzinger_memory:.2f}x Standard\",\n",
    "        f\"{best_point_improvement['Implementation']} ({best_point_improvement['Value']:+.1f}%)\",\n",
    "        f\"{best_range_improvement['Implementation']} ({best_range_improvement['Value']:+.1f}%)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "key_stats_df = pd.DataFrame(key_stats)\n",
    "key_stats_df.to_csv('../benchmarks/fence_pointer_key_stats.csv', index=False)\n",
    "display(key_stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}